group = interaction(treatment_group, missing),
color = treatment_group, linetype = missing)) +
geom_line() +
labs(title = "Mean Memory Computation by Treatment Group over Days",
subtitle = "Differentiated by Missing Level",
x = "Day",
y = "Mean Memory Computation",
color = "Treatment Group",
linetype = "Missing Level") +
theme_minimal()
full_data %>%
group_by(treatment_group, day, missing) %>%
summarise(mean_mem_comp = mean(mem_comp, na.rm = TRUE), .groups = 'drop') %>%
ggplot(aes(x = day, y = mean_mem_comp,
group = interaction(treatment_group, missing),
color = treatment_group, linetype = missing)) +
geom_line() +
labs(title = "Mean Memory Computation by Treatment Group over Days",
subtitle = "Differentiated by Missing Level",
x = "Day",
y = "Mean Memory Computation",
color = "Treatment Group",
linetype = "Missing Level") +
scale_linetype_manual("Present" = "solid", "Missing" = "dashed")+
theme_minimal()
full_data %>%
group_by(treatment_group, day, missing) %>%
summarise(mean_mem_comp = mean(mem_comp, na.rm = TRUE), .groups = 'drop') %>%
ggplot(aes(x = day, y = mean_mem_comp,
group = interaction(treatment_group, missing),
color = treatment_group, linetype = missing)) +
geom_line() +
labs(title = "Mean Memory Computation by Treatment Group over Days",
subtitle = "Differentiated by Missing Level",
x = "Day",
y = "Mean Memory Computation",
color = "Treatment Group",
linetype = "Missing Level") +
scale_linetype_manual(values = c("Present" = "solid", "Missing" = "dashed"))+
theme_minimal()
full_data %>%
group_by(treatment_group, day, missing) %>%
summarise(mean_mem_comp = mean(mem_comp, na.rm = TRUE), .groups = 'drop') %>%
ggplot(aes(x = day, y = mean_mem_comp,
#group = interaction(treatment_group, missing),
color = treatment_group, linetype = missing)) +
geom_line() +
labs(title = "Mean Memory Computation by Treatment Group over Days",
subtitle = "Differentiated by Missing Level",
x = "Day",
y = "Mean Memory Computation",
color = "Treatment Group",
linetype = "Missing Level") +
scale_linetype_manual(values = c("Present" = "solid", "Missing" = "dashed"))+
theme_minimal()
full_data %>%
group_by(treatment_group, day, missing) %>%
summarise(mean_mem_comp = mean(mem_comp, na.rm = TRUE), .groups = 'drop') %>%
ggplot(aes(x = day, y = mean_mem_comp,
group = interaction(treatment_group, missing),
color = treatment_group)) +
geom_line() +
labs(title = "Mean Memory Computation by Treatment Group over Days",
subtitle = "Differentiated by Missing Level",
x = "Day",
y = "Mean Memory Computation",
color = "Treatment Group",
linetype = "Missing Level") +
scale_linetype_manual(values = c("Present" = "solid", "Missing" = "dashed"))+
theme_minimal()
full_data %>%
group_by(treatment_group, day, missing) %>%
summarise(mean_mem_comp = mean(mem_comp, na.rm = TRUE), .groups = 'drop') %>%
ggplot(aes(x = day, y = mean_mem_comp,
group = interaction(treatment_group, missing),
color = treatment_group, linetype = missing)) +
geom_line() +
labs(title = "Mean Memory Computation by Treatment Group over Days",
subtitle = "Differentiated by Missing Level",
x = "Day",
y = "Mean Memory Computation",
color = "Treatment Group",
linetype = "Missing Level") +
scale_linetype_manual(values = c("Present" = "solid", "Missing" = "dashed"))+
theme_minimal()
full_data %>%
group_by(treatment_group, day, missing) %>%
ungroup() %>%
summarise(mean_mem_comp = mean(mem_comp, na.rm = TRUE), .groups = 'drop') %>%
ggplot(aes(x = day, y = mean_mem_comp,
group = interaction(treatment_group, missing),
color = treatment_group, linetype = missing)) +
geom_line() +
labs(title = "Mean Memory Computation by Treatment Group over Days",
subtitle = "Differentiated by Missing Level",
x = "Day",
y = "Mean Memory Computation",
color = "Treatment Group",
linetype = "Missing Level") +
scale_linetype_manual(values = c("Present" = "solid", "Missing" = "dashed"))+
theme_minimal()
full_data %>%
group_by(treatment_group, day, missing) %>%
summarise(mean_mem_comp = mean(mem_comp, na.rm = TRUE), .groups = 'drop') %>%
ungroup() %>%
ggplot(aes(x = day, y = mean_mem_comp,
group = interaction(treatment_group, missing),
color = treatment_group, linetype = missing)) +
geom_line() +
labs(title = "Mean Memory Computation by Treatment Group over Days",
subtitle = "Differentiated by Missing Level",
x = "Day",
y = "Mean Memory Computation",
color = "Treatment Group",
linetype = "Missing Level") +
scale_linetype_manual(values = c("Present" = "solid", "Missing" = "dashed"))+
theme_minimal()
full_data %>%
group_by(treatment_group, day, missing) %>%
summarise(mean_mem_comp = mean(mem_comp, na.rm = TRUE)) %>%
ungroup() %>%
ggplot(aes(x = day, y = mean_mem_comp,
group = interaction(treatment_group, missing),
color = treatment_group, linetype = missing)) +
geom_line() +
labs(title = "Mean Memory Computation by Treatment Group over Days",
subtitle = "Differentiated by Missing Level",
x = "Day",
y = "Mean Memory Computation",
color = "Treatment Group",
linetype = "Missing Level") +
scale_linetype_manual(values = c("Present" = "solid", "Missing" = "dashed"))+
theme_minimal()
# Load the necessary libraries
library(rstan)
library(splines)
# Define the number of basis functions (k) and discretization points (d)
k <- 20
d <- 50
# Define the equally spaced discretization points on [0, 1]
t <- seq(0, 1, length.out = d)
# Generate the B-spline evaluation matrix Theta using the bs() function
Theta <- bs(t, df = k, degree = 3, intercept = TRUE)
# Define the penalty matrix P, which is often a second derivative matrix to enforce smoothness
# For example, using a finite difference approximation for the second derivative
P <- diff(diag(k), differences = 2)
# Assuming P is invertible, if not, you might need to add a small constant to the diagonal
P_inv <- solve(P)
# Construct a second-order difference matrix
D2 <- diff(diag(k), differences = 2)
# The penalty matrix is then D2' * D2 to ensure it is square and positive semi-definite
P <- t(D2) %*% D2
# Since P is positive semi-definite and not full rank (due to boundary conditions of splines),
# we cannot directly invert it. We need to use a generalized inverse, such as the Moore-Penrose pseudoinverse.
P_inv <- MASS::ginv(P)
# Set the Stan model code as a string
stan_model_code <- "
data {
int<lower=1> k; // Number of spline coefficients
int<lower=1> d; // Number of discretization points
matrix[d, k] Theta; // B-spline evaluation matrix
matrix[k, k] P_inv; // Inverse of the penalty matrix
}
parameters {
vector[k] gamma; // Spline coefficients
real<lower=0> sigma_gamma; // Standard deviation for the spline coefficients
}
model {
// Priors
gamma ~ multi_normal_prec(rep_vector(0, k), sigma_gamma * P_inv);
// You can add more priors here, for example for sigma_gamma
// We don't have data here, but you can add a data likelihood part if you have data
// For now, we just have the prior model
}
"
# Compile the model
stan_model <- stan_model(model_code = stan_model_code)
# Define the data list to be passed to the Stan model
stan_data <- list(k = k, d = d, Theta = Theta, P_inv = P_inv)
# Perform sampling
fit <- sampling(stan_model, data = stan_data, iter = 2000, chains = 4)
# Compile the model
stan_model <- stan_model(model_code = stan_model_code)
# Define the data list to be passed to the Stan model
stan_data <- list(k = k, d = d, Theta = Theta, P_inv = P_inv)
# Perform sampling
fit <- sampling(stan_model, data = stan_data, iter = 2000, chains = 4)
# Function to generate initial values
init_fun <- function() {
list(gamma = rnorm(k, 0, 1), sigma_gamma = runif(1, 0.1, 2))
}
# Fit the model with initial values
fit <- sampling(stan_model, data = stan_data, init = init_fun, iter = 2000, chains = 4)
# Add a small constant to the diagonal of P before inverting
P <- t(D2) %*% D2 + diag(1e-6, k)
# Since P is positive semi-definite and not full rank (due to boundary conditions of splines),
# we cannot directly invert it. We need to use a generalized inverse, such as the Moore-Penrose pseudoinverse.
P_inv <- MASS::ginv(P)
# Set the Stan model code as a string
stan_model_code <- "
data {
int<lower=1> k; // Number of spline coefficients
int<lower=1> d; // Number of discretization points
matrix[d, k] Theta; // B-spline evaluation matrix
matrix[k, k] P_inv; // Inverse of the penalty matrix
}
parameters {
vector[k] gamma; // Spline coefficients
real<lower=0> sigma_gamma; // Standard deviation for the spline coefficients
}
model {
// Priors
gamma ~ multi_normal_prec(rep_vector(0, k), sigma_gamma * P_inv);
// You can add more priors here, for example for sigma_gamma
// We don't have data here, but you can add a data likelihood part if you have data
// For now, we just have the prior model
}
"
# Function to generate initial values
init_fun <- function() {
list(gamma = rnorm(k, 0, 1), sigma_gamma = runif(1, 0.1, 2))
}
# Fit the model with initial values
fit <- sampling(stan_model, data = stan_data, init = init_fun, iter = 2000, chains = 4)
# Compile the model
stan_model <- stan_model(model_code = stan_model_code)
# Define the data list to be passed to the Stan model
stan_data <- list(k = k, d = d, Theta = Theta, P_inv = P_inv)
# Perform sampling
fit <- sampling(stan_model, data = stan_data, iter = 2000, chains = 4)
# Set the Stan model code as a string
stan_model_code <- "
data {
int<lower=1> k; // Number of spline coefficients
int<lower=1> d; // Number of discretization points
matrix[d, k] Theta; // B-spline evaluation matrix
matrix[k, k] P; // Penalty matrix
}
parameters {
vector[k] gamma; // Spline coefficients
real<lower=0> sigma_gamma; // Standard deviation for the spline coefficients
cholesky_factor_cov[k] L_Omega; // Cholesky factor of the precision matrix
}
model {
// Priors
gamma ~ multi_normal_cholesky(rep_vector(0, k), sigma_gamma * L_Omega);
// You can add more priors here, for example for sigma_gamma
// The likelihood would go here if we had data
}
"
# Function to generate initial values
init_fun <- function() {
list(gamma = rnorm(k, 0, 1), sigma_gamma = runif(1, 0.1, 2))
}
# Fit the model with initial values
fit <- sampling(stan_model, data = stan_data, init = init_fun, iter = 2000, chains = 4)
# Compile the model
stan_model <- stan_model(model_code = stan_model_code)
# Define the data list to be passed to the Stan model
stan_data <- list(k = k, d = d, Theta = Theta, P_inv = P_inv)
# Perform sampling
fit <- sampling(stan_model, data = stan_data, iter = 2000, chains = 4)
# Function to generate initial values
init_fun <- function() {
list(gamma = rnorm(k, 0, 1), sigma_gamma = runif(1, 0.1, 2))
}
# Fit the model with initial values
fit <- sampling(stan_model, data = stan_data, init = init_fun, iter = 2000, chains = 4)
P_inv <- solve(P)
# Set the Stan model code as a string
stan_model_code <- "
data {
int<lower=1> k; // Number of spline coefficients
int<lower=1> d; // Number of discretization points
matrix[d, k] Theta; // B-spline evaluation matrix
matrix[k, k] P; // Penalty matrix
}
parameters {
vector[k] gamma; // Spline coefficients
real<lower=0> sigma_gamma; // Standard deviation for the spline coefficients
cholesky_factor_cov[k] L_Omega; // Cholesky factor of the precision matrix
}
model {
// Priors
gamma ~ multi_normal_cholesky(rep_vector(0, k), sigma_gamma * L_Omega);
// You can add more priors here, for example for sigma_gamma
// The likelihood would go here if we had data
}
"
# Compile the model
stan_model <- stan_model(model_code = stan_model_code)
# Define the data list to be passed to the Stan model
stan_data <- list(k = k, d = d, Theta = Theta, P_inv = P_inv)
# Function to generate initial values
init_fun <- function() {
list(gamma = rnorm(k, 0, 1), sigma_gamma = runif(1, 0.1, 2))
}
# Fit the model with initial values
fit <- sampling(stan_model, data = stan_data, init = init_fun, iter = 2000, chains = 4)
# Perform sampling
fit <- sampling(stan_model, data = stan_data, iter = 2000, chains = 4)
# Define the data list to be passed to the Stan model
# Define the data list to be passed to the Stan model
stan_data <- list(k = k, d = d, Theta = Theta, P = P)
# Perform sampling
fit <- sampling(stan_model, data = stan_data, iter = 2000, chains = 4)
# Print the summary of the fit
print(fit)
# Extract the samples for gamma and sigma_gamma
gamma_samples <- extract(fit)$gamma
sigma_gamma_samples <- extract(fit)$sigma_gamma
gamma_samples
sigma_gamma_samples
dim(gamma_samples)
dim(sigma_gamma_samples)
extract(fit)
names(extract(fit))
L_c <- extract(fit)$L_Omega
dim(L_c)
dim(stan_data)
stan_data
stan_data$Theta
names(stan_data)
View(stan_data)
stan_data[["Theta"]]
View(fit)
library(survival)
library(ggsurvfit)
install.packages("ggsurvfit")
library(ggsurvfit)
dat <- read.table("Menopause.dat")
getwd()
library(rstudioapi)
## set working directory to wherever this file is located ##
current_path <- getActiveDocumentContext()$path
setwd(dirname(current_path ))
dat <- read.table("Menopause.dat")
View(dat)
colnames(dat) <- c("id", "intake_age", "menopause_age", "menopause", "race", "education")
dat$menopause_time <- dat$menopause_age-dat$intake_age
fit <- survfit(Surv(menopause_time, menopause)~1, data = dat, conf.type = "log-log")
fit_summary <- summary(fit)
quantile(fit, probs = c(0.5), conf.int = TRUE)
survfit2(Surv(menopause_time, menopause)~1, data = dat, conf.type = "log-log") %>%
ggsurvfit() +
add_risktable() +
add_confidence_interval() +
add_quantile() +
add_censor_mark()
#dat$gender <- as.factor(dat$gender)
table1<- table1(~ menopause_age + intake_age + menopause_time + race +education | data=dat)
#dat$gender <- as.factor(dat$gender)
table1<- table1(~ menopause_age + intake_age + menopause_time + race +education|data=dat)
?table1
names(dat)
sum(dat$menopause)
#dat$gender <- as.factor(dat$gender)
table1<- table1(~ menopause_age + intake_age + menopause_time + race +education| menopause, data=dat)
library(table1)
#dat$gender <- as.factor(dat$gender)
table1<- table1(~ menopause_age + intake_age + menopause_time + race +education| menopause, data=dat)
dat$menopause <- as.factor(dat$menopause)
names(dat)
#dat$gender <- as.factor(dat$gender)
table1<- table1(~ menopause_age + intake_age + menopause_time + race +education| menopause, data=dat)
table1_viral<- table1(~ bviral0  + bviral1+bviral2+bviral3+bviral4+bviral5+bviral6+ sviral0++ sviral1+ sviral2+ sviral3+ sviral4+ sviral5+ sviral6|trt_order, data=baseline)
table1
xtable(as.data.frame(table1))
library(xtable)
xtable(as.data.frame(table1))
names(dat)
dat$race <- as.factor(dat$race)
dat$education <- as.factor(dat$education)
names(dat)
#dat$gender <- as.factor(dat$gender)
table1<- table1(~ menopause_age + intake_age + menopause_time + race +education| menopause, data=dat)
xtable(as.data.frame(table1))
table1
library(survival)
library(ggsurvfit)
library(survminer)
library(survminer)
library(flexsurv)
library(survMisc)
dat <- read.table("Menopause.dat")
colnames(dat) <- c("id", "intake_age", "menopause_age", "menopause", "race", "education")
dat$menopause_time <- dat$menopause_age-dat$intake_age
### 1a
fit_exp <- survreg(Surv(menopause_time, menopause)~1, data = dat, dist = "exponential")
summary(fit_exp)
### 1b
fit_KM <- survfit(Surv(menopause_time, menopause)~1, data = dat, conf.type = "log-log")
fit_summary <- summary(fit_KM)
quantile(fit_KM, probs = c(0.5), conf.int = TRUE)
survfit2(Surv(menopause_time, menopause)~1, data = dat, conf.type = "log-log") %>%
ggsurvfit() +
add_risktable() +
add_confidence_interval() +
add_quantile() +
add_censor_mark()
fit_summary
library(survival)
library(ggsurvfit)
library(survminer)
library(flexsurv)
library(survMisc)
dat <- read.table("Menopause.dat")
colnames(dat) <- c("id", "intake_age", "menopause_age", "menopause", "race", "education")
dat$menopause_time <- dat$menopause_age-dat$intake_age
### 1a
fit_exp <- survreg(Surv(menopause_time, menopause)~1, data = dat, dist = "exponential")
summary(fit_exp)
### 1b
fit_KM <- survfit(Surv(menopause_time, menopause)~1, data = dat, conf.type = "log-log")
fit_summary <- summary(fit_KM)
fit_summary
quantile(fit_KM, probs = c(0.5), conf.int = TRUE)
quantile(fit_KM, probs = c(0.5), conf.int = TRUE)
survfit2(Surv(menopause_time, menopause)~1, data = dat, conf.type = "log-log") %>%
ggsurvfit() +
add_risktable() +
add_confidence_interval() +
add_quantile() +
add_censor_mark()
fit_exp
plot(fit, conf.int = T, mark = "+", xlab = "Time", ylab = "Survival probability")
### 1a
fit_exp <- survreg(Surv(menopause_time, menopause)~1, data = dat, dist = "exponential")
summary(fit_exp)
### 1b
fit_KM <- survfit(Surv(menopause_time, menopause)~1, data = dat, conf.type = "log-log")
fit_summary <- summary(fit_KM)
quantile(fit_KM, probs = c(0.5), conf.int = TRUE)
survfit2(Surv(menopause_time, menopause)~1, data = dat, conf.type = "log-log") %>%
ggsurvfit() +
add_risktable() +
add_confidence_interval() +
add_quantile() +
add_censor_mark()
### 3
#fit_exp_2 <- survreg(Surv(intake_age, menopause_age, menopause)~1, data = dat, dist = "exponential")
fit_exp_2 <- flexsurvreg(Surv(intake_age, menopause_age, menopause)~1, data = dat, dist = "exponential")
fit_exp_2
fit_exp_2$coefficients
fit_KM_2 <- survfit(Surv(intake_age,menopause_age, menopause)~1, data = dat, conf.type = "log-log")
fit_summary <- summary(fit_KM_2)
quantile(fit_KM_2, probs = c(0.5), conf.int = TRUE)
survfit2(Surv(intake_age, menopause_age, menopause)~1, data = dat, conf.type = "log-log") %>%
ggsurvfit() +
add_risktable() +
add_confidence_interval() +
add_quantile() +
add_censor_mark()
ggcoxzph(test_ph)
fit_ph <- coxph(Surv(menopause_time, menopause)~as.factor(race)+as.factor(education)+intake_age, data = dat)
summary(fit_ph)
test_ph <- cox.zph(fit_ph)
ggcoxzph(test_ph)
### 3
#fit_exp_2 <- survreg(Surv(intake_age, menopause_age, menopause)~1, data = dat, dist = "exponential")
fit_exp_2 <- flexsurvreg(Surv(intake_age, menopause_age, menopause)~1, data = dat, dist = "exponential")
fit_exp_2$coefficients
fit_KM_2 <- survfit(Surv(intake_age,menopause_age, menopause)~1, data = dat, conf.type = "log-log")
fit_summary <- summary(fit_KM_2)
quantile(fit_KM_2, probs = c(0.5), conf.int = TRUE)
survfit2(Surv(intake_age, menopause_age, menopause)~1, data = dat, conf.type = "log-log") %>%
ggsurvfit() +
add_risktable() +
add_confidence_interval() +
add_quantile() +
add_censor_mark()
dat <- read.table("Menopause.dat")
colnames(dat) <- c("id", "intake_age", "menopause_age", "menopause", "race", "education")
dat$menopause_time <- dat$menopause_age-dat$intake_age
### 1a
fit_exp <- survreg(Surv(menopause_time, menopause)~1, data = dat, dist = "exponential")
summary(fit_exp)
### 1b
fit_KM <- survfit(Surv(menopause_time, menopause)~1, data = dat, conf.type = "log-log")
fit_summary <- summary(fit_KM)
quantile(fit_KM, probs = c(0.5), conf.int = TRUE)
#plot(fit, conf.int = T, mark = "+", xlab = "Time", ylab = "Survival probability")
survfit2(Surv(menopause_time, menopause)~1, data = dat, conf.type = "log-log") %>%
ggsurvfit() +
add_risktable() +
add_confidence_interval() +
add_quantile() +
add_censor_mark()
fit_summary
summary(survfit2(Surv(menopause_time, menopause)~1, data = dat, conf.type = "log-log"))
library(survival)
library(ggsurvfit)
library(survminer)
library(flexsurv)
library(survMisc)
dat <- read.table("Menopause.dat")
colnames(dat) <- c("id", "intake_age", "menopause_age", "menopause", "race", "education")
dat$menopause_time <- dat$menopause_age-dat$intake_age
### 1a
fit_exp <- survreg(Surv(menopause_time, menopause)~1, data = dat, dist = "exponential")
summary(fit_exp)
### 1b
fit_KM <- survfit(Surv(menopause_time, menopause)~1, data = dat, conf.type = "log-log")
fit_summary <- summary(fit_KM)
fit_summary
fit_ph <- coxph(Surv(menopause_time, menopause)~as.factor(race)+as.factor(education)+intake_age, data = dat)
summary(fit_ph)
test_ph <- cox.zph(fit_ph)
ggcoxzph(test_ph)
test_ph
xtable(summary(fit_ph))
?flexsurvreg
